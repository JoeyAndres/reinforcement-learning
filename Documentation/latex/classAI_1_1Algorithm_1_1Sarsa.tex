\hypertarget{classAI_1_1Algorithm_1_1Sarsa}{\section{A\-I\-:\-:Algorithm\-:\-:Sarsa$<$ S, A $>$ Class Template Reference}
\label{classAI_1_1Algorithm_1_1Sarsa}\index{A\-I\-::\-Algorithm\-::\-Sarsa$<$ S, A $>$@{A\-I\-::\-Algorithm\-::\-Sarsa$<$ S, A $>$}}
}


{\ttfamily \#include $<$Sarsa.\-h$>$}

Inheritance diagram for A\-I\-:\-:Algorithm\-:\-:Sarsa$<$ S, A $>$\-:\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[height=4.000000cm]{classAI_1_1Algorithm_1_1Sarsa}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\hyperlink{classAI_1_1Algorithm_1_1Sarsa_afbf9b70589b234a07f4516aecd359fda}{Sarsa} (A\-I\-::\-F\-L\-O\-A\-T step\-Size, A\-I\-::\-F\-L\-O\-A\-T discount\-Rate, \hyperlink{classAI_1_1Algorithm_1_1Policy}{Policy}$<$ S, A $>$ \&policy)
\item 
virtual void \hyperlink{classAI_1_1Algorithm_1_1Sarsa_ae1d62478d3e31cace3fb594e05f83d1c}{update} (const \hyperlink{classAI_1_1StateAction}{State\-Action}$<$ S, A $>$ \&current\-State\-Action, const S \&next\-State, const A\-I\-::\-F\-L\-O\-A\-T reward, const set$<$ A $>$ \&action\-Set)
\end{DoxyCompactItemize}
\subsection*{Additional Inherited Members}


\subsection{Detailed Description}
\subsubsection*{template$<$class S, class A$>$class A\-I\-::\-Algorithm\-::\-Sarsa$<$ S, A $>$}

\hyperlink{classAI_1_1Algorithm_1_1Sarsa}{Sarsa} 

An implementation of T\-D(0) that employs On-\/\-Policy T\-D Control. Meaning the same policy is used for approximating q$\ast$ and action-\/selection. 

\subsection{Constructor \& Destructor Documentation}
\hypertarget{classAI_1_1Algorithm_1_1Sarsa_afbf9b70589b234a07f4516aecd359fda}{\index{A\-I\-::\-Algorithm\-::\-Sarsa@{A\-I\-::\-Algorithm\-::\-Sarsa}!Sarsa@{Sarsa}}
\index{Sarsa@{Sarsa}!AI::Algorithm::Sarsa@{A\-I\-::\-Algorithm\-::\-Sarsa}}
\subsubsection[{Sarsa}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class S , class A $>$ {\bf A\-I\-::\-Algorithm\-::\-Sarsa}$<$ S, A $>$\-::{\bf Sarsa} (
\begin{DoxyParamCaption}
\item[{A\-I\-::\-F\-L\-O\-A\-T}]{step\-Size, }
\item[{A\-I\-::\-F\-L\-O\-A\-T}]{discount\-Rate, }
\item[{{\bf Policy}$<$ S, A $>$ \&}]{policy}
\end{DoxyParamCaption}
)}}\label{classAI_1_1Algorithm_1_1Sarsa_afbf9b70589b234a07f4516aecd359fda}

\begin{DoxyParams}{Parameters}
{\em greedy} & determines how random is get\-Next\-State() is. A value of 1.\-0 means get\-Next\-State returns based on current likelihood of a state occuring (not random). With 0.\-0, it will not rely on the likelihood of state and return a random nextstate. \\
\hline
{\em step\-Size} & determines how the frequency is updated. A low value yields to a more accurate model of the environment but slower in learning environment. A value of 1.\-0 yields to forgeting the frequency information of all other transition states, suitable for deterministic environment. \\
\hline
\end{DoxyParams}


\subsection{Member Function Documentation}
\hypertarget{classAI_1_1Algorithm_1_1Sarsa_ae1d62478d3e31cace3fb594e05f83d1c}{\index{A\-I\-::\-Algorithm\-::\-Sarsa@{A\-I\-::\-Algorithm\-::\-Sarsa}!update@{update}}
\index{update@{update}!AI::Algorithm::Sarsa@{A\-I\-::\-Algorithm\-::\-Sarsa}}
\subsubsection[{update}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class S , class A $>$ void {\bf A\-I\-::\-Algorithm\-::\-Sarsa}$<$ S, A $>$\-::update (
\begin{DoxyParamCaption}
\item[{const {\bf State\-Action}$<$ S, A $>$ \&}]{current\-State\-Action, }
\item[{const S \&}]{next\-State, }
\item[{const A\-I\-::\-F\-L\-O\-A\-T}]{reward, }
\item[{const set$<$ A $>$ \&}]{action\-Set}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [virtual]}}}\label{classAI_1_1Algorithm_1_1Sarsa_ae1d62478d3e31cace3fb594e05f83d1c}
Update the state\-Action map. 
\begin{DoxyParams}{Parameters}
{\em current\-State} & \\
\hline
{\em current\-Action} & \\
\hline
{\em next\-State} & \\
\hline
{\em reward} & reward of the current state action value. \\
\hline
{\em action\-Set} & A set of all actions. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
next action to be executed. 
\end{DoxyReturn}


Reimplemented from \hyperlink{classAI_1_1Algorithm_1_1ReinforcementLearning_a25d7fa245a79e61061436dc0f1db90cb}{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning$<$ S, A $>$}.



Reimplemented in \hyperlink{classAI_1_1Algorithm_1_1SarsaET_adf13376b7ec8fdfa2b19ffadb1aa81e7}{A\-I\-::\-Algorithm\-::\-Sarsa\-E\-T$<$ S, A $>$}.



The documentation for this class was generated from the following file\-:\begin{DoxyCompactItemize}
\item 
Algorithms/\-Reinforcement\-Learning/Sarsa.\-h\end{DoxyCompactItemize}
