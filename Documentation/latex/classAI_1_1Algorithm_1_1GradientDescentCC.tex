\hypertarget{classAI_1_1Algorithm_1_1GradientDescentCC}{\section{A\+I\+:\+:Algorithm\+:\+:Gradient\+Descent\+C\+C Class Reference}
\label{classAI_1_1Algorithm_1_1GradientDescentCC}\index{A\+I\+::\+Algorithm\+::\+Gradient\+Descent\+C\+C@{A\+I\+::\+Algorithm\+::\+Gradient\+Descent\+C\+C}}
}


Just an experimental concurrent version of Gradient Descent. This is not recommended to be utilize yet since Work in Progress.  




{\ttfamily \#include $<$Gradient\+Descent\+C\+C.\+h$>$}

Inheritance diagram for A\+I\+:\+:Algorithm\+:\+:Gradient\+Descent\+C\+C\+:\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[height=2.000000cm]{classAI_1_1Algorithm_1_1GradientDescentCC}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\hypertarget{classAI_1_1Algorithm_1_1GradientDescentCC_a036943a3f05d8e9146e833d225b13d74}{{\bfseries Gradient\+Descent\+C\+C} (\hyperlink{classAI_1_1Algorithm_1_1TileCode}{Tile\+Code} \&tile\+Code, \hyperlink{namespaceAI_a41b74884a20833db653dded3918e05c3}{A\+I\+::\+F\+L\+O\+A\+T} step\+Size, \hyperlink{namespaceAI_a41b74884a20833db653dded3918e05c3}{A\+I\+::\+F\+L\+O\+A\+T} discount\+Rate, \hyperlink{namespaceAI_a41b74884a20833db653dded3918e05c3}{A\+I\+::\+F\+L\+O\+A\+T} lambda)}\label{classAI_1_1Algorithm_1_1GradientDescentCC_a036943a3f05d8e9146e833d225b13d74}

\item 
virtual void \hyperlink{classAI_1_1Algorithm_1_1GradientDescentCC_a5cd9bd033e8556b4961370da3298cfce}{decrease\+Eligibility\+Traces} ()
\item 
virtual void \hyperlink{classAI_1_1Algorithm_1_1GradientDescentCC_a990c4b429edd9583e0e0a56be43faad8}{back\+Up\+Weights} (\hyperlink{namespaceAI_a41b74884a20833db653dded3918e05c3}{F\+L\+O\+A\+T} td\+Error)
\end{DoxyCompactItemize}
\subsection*{Protected Member Functions}
\begin{DoxyCompactItemize}
\item 
\hypertarget{classAI_1_1Algorithm_1_1GradientDescentCC_a671233415fd282b198c6d0999e63832a}{virtual void {\bfseries \+\_\+decrease\+Eligibility\+Traces\+Worker} (\hyperlink{namespaceAI_ab6e14dc1e659854858a87e511f1439ec}{A\+I\+::\+U\+I\+N\+T} starti, \hyperlink{namespaceAI_ab6e14dc1e659854858a87e511f1439ec}{A\+I\+::\+U\+I\+N\+T} length)}\label{classAI_1_1Algorithm_1_1GradientDescentCC_a671233415fd282b198c6d0999e63832a}

\item 
\hypertarget{classAI_1_1Algorithm_1_1GradientDescentCC_a647a9d1f60731c366695a7c1fac008d4}{virtual void {\bfseries \+\_\+back\+Up\+Weights\+Worker} (\hyperlink{namespaceAI_a41b74884a20833db653dded3918e05c3}{F\+L\+O\+A\+T} td\+Error, \hyperlink{namespaceAI_ab6e14dc1e659854858a87e511f1439ec}{A\+I\+::\+U\+I\+N\+T} starti, \hyperlink{namespaceAI_ab6e14dc1e659854858a87e511f1439ec}{A\+I\+::\+U\+I\+N\+T} length)}\label{classAI_1_1Algorithm_1_1GradientDescentCC_a647a9d1f60731c366695a7c1fac008d4}

\end{DoxyCompactItemize}
\subsection*{Additional Inherited Members}


\subsection{Detailed Description}
Just an experimental concurrent version of Gradient Descent. This is not recommended to be utilize yet since Work in Progress. 

\subsection{Member Function Documentation}
\hypertarget{classAI_1_1Algorithm_1_1GradientDescentCC_a990c4b429edd9583e0e0a56be43faad8}{\index{A\+I\+::\+Algorithm\+::\+Gradient\+Descent\+C\+C@{A\+I\+::\+Algorithm\+::\+Gradient\+Descent\+C\+C}!back\+Up\+Weights@{back\+Up\+Weights}}
\index{back\+Up\+Weights@{back\+Up\+Weights}!A\+I\+::\+Algorithm\+::\+Gradient\+Descent\+C\+C@{A\+I\+::\+Algorithm\+::\+Gradient\+Descent\+C\+C}}
\subsubsection[{back\+Up\+Weights}]{\setlength{\rightskip}{0pt plus 5cm}void A\+I\+::\+Algorithm\+::\+Gradient\+Descent\+C\+C\+::back\+Up\+Weights (
\begin{DoxyParamCaption}
\item[{{\bf F\+L\+O\+A\+T}}]{td\+Error}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [virtual]}}}\label{classAI_1_1Algorithm_1_1GradientDescentCC_a990c4b429edd9583e0e0a56be43faad8}
Update weights with tderror. 
\begin{DoxyParams}{Parameters}
{\em td\+Error} & \\
\hline
\end{DoxyParams}


Reimplemented from \hyperlink{classAI_1_1Algorithm_1_1GradientDescent_a49b556716f8ca93c088b10f4432a3688}{A\+I\+::\+Algorithm\+::\+Gradient\+Descent}.

\hypertarget{classAI_1_1Algorithm_1_1GradientDescentCC_a5cd9bd033e8556b4961370da3298cfce}{\index{A\+I\+::\+Algorithm\+::\+Gradient\+Descent\+C\+C@{A\+I\+::\+Algorithm\+::\+Gradient\+Descent\+C\+C}!decrease\+Eligibility\+Traces@{decrease\+Eligibility\+Traces}}
\index{decrease\+Eligibility\+Traces@{decrease\+Eligibility\+Traces}!A\+I\+::\+Algorithm\+::\+Gradient\+Descent\+C\+C@{A\+I\+::\+Algorithm\+::\+Gradient\+Descent\+C\+C}}
\subsubsection[{decrease\+Eligibility\+Traces}]{\setlength{\rightskip}{0pt plus 5cm}void A\+I\+::\+Algorithm\+::\+Gradient\+Descent\+C\+C\+::decrease\+Eligibility\+Traces (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [virtual]}}}\label{classAI_1_1Algorithm_1_1GradientDescentCC_a5cd9bd033e8556b4961370da3298cfce}
Decrease each eligibility traces by eligibility traces and discount rate \$()\$ 

Reimplemented from \hyperlink{classAI_1_1Algorithm_1_1GradientDescent_a5c5ae472417bc016fdd185875614359d}{A\+I\+::\+Algorithm\+::\+Gradient\+Descent}.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
Algorithms/\+Supervised\+Learning/Gradient\+Descent\+C\+C.\+h\end{DoxyCompactItemize}
