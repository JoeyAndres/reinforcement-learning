\hypertarget{classAI_1_1Algorithm_1_1ReinforcementLearning}{\section{A\-I\-:\-:Algorithm\-:\-:Reinforcement\-Learning$<$ S, A $>$ Class Template Reference}
\label{classAI_1_1Algorithm_1_1ReinforcementLearning}\index{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning$<$ S, A $>$@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning$<$ S, A $>$}}
}


Abstract class for all Reinforcement learning algorithms.  




{\ttfamily \#include $<$Reinforcement\-Learning.\-h$>$}

Inheritance diagram for A\-I\-:\-:Algorithm\-:\-:Reinforcement\-Learning$<$ S, A $>$\-:\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[height=2.397260cm]{classAI_1_1Algorithm_1_1ReinforcementLearning}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\hyperlink{classAI_1_1Algorithm_1_1ReinforcementLearning_a4d182d91c68aef838b80843acd044b1e}{Reinforcement\-Learning} (\hyperlink{namespaceAI_a41b74884a20833db653dded3918e05c3}{A\-I\-::\-F\-L\-O\-A\-T} step\-Size, \hyperlink{namespaceAI_a41b74884a20833db653dded3918e05c3}{A\-I\-::\-F\-L\-O\-A\-T} discount\-Rate, \hyperlink{classAI_1_1Algorithm_1_1Policy_1_1Policy}{Policy\-::\-Policy}$<$ S, A $>$ \&policy)
\item 
A \hyperlink{classAI_1_1Algorithm_1_1ReinforcementLearning_ad1d8a8ebb47fb71a53b15b770795e286}{arg\-Max} (const S \&state, const set$<$ A $>$ \&action\-Set) const 
\item 
virtual \hyperlink{namespaceAI_a41b74884a20833db653dded3918e05c3}{A\-I\-::\-F\-L\-O\-A\-T} \hyperlink{classAI_1_1Algorithm_1_1ReinforcementLearning_a04edb957e23dde9c6733668ad844c32b}{get\-Discount\-Rate} () const 
\item 
virtual void \hyperlink{classAI_1_1Algorithm_1_1ReinforcementLearning_a1fc1e11a3ddb4377c4d6813a95ce87f4}{set\-Discount\-Rate} (\hyperlink{namespaceAI_a41b74884a20833db653dded3918e05c3}{A\-I\-::\-F\-L\-O\-A\-T} discount\-Rate)
\item 
virtual \hyperlink{namespaceAI_a41b74884a20833db653dded3918e05c3}{A\-I\-::\-F\-L\-O\-A\-T} \hyperlink{classAI_1_1Algorithm_1_1ReinforcementLearning_a13e6c161a33644183d3d357971eeaaf5}{get\-Step\-Size} () const 
\item 
virtual void \hyperlink{classAI_1_1Algorithm_1_1ReinforcementLearning_a04932645faa6c385e4c587f7f845b484}{set\-Step\-Size} (\hyperlink{namespaceAI_a41b74884a20833db653dded3918e05c3}{A\-I\-::\-F\-L\-O\-A\-T} step\-Size)
\item 
virtual void \hyperlink{classAI_1_1Algorithm_1_1ReinforcementLearning_aa45b49ec954f6934df4d541b70076bd6}{back\-Up\-State\-Action\-Pair} (const \hyperlink{classAI_1_1StateAction}{State\-Action}$<$ S, A $>$ \&current\-State\-Action, const \hyperlink{namespaceAI_a41b74884a20833db653dded3918e05c3}{A\-I\-::\-F\-L\-O\-A\-T} reward, const \hyperlink{classAI_1_1StateAction}{State\-Action}$<$ S, A $>$ \&next\-State\-Action\-Pair)
\item 
const A \& \hyperlink{classAI_1_1Algorithm_1_1ReinforcementLearning_a9f31822bf51b07d17b31d7683d7e25a2}{get\-Learning\-Action} (const S \&current\-State, const set$<$ A $>$ \&action\-Set)
\item 
virtual \hyperlink{namespaceAI_a41b74884a20833db653dded3918e05c3}{A\-I\-::\-F\-L\-O\-A\-T} \hyperlink{classAI_1_1Algorithm_1_1ReinforcementLearning_ad078677d92b33df4ae7d3c78e040b766}{get\-State\-Action\-Value} (const \hyperlink{classAI_1_1StateAction}{State\-Action}$<$ S, A $>$ \&state\-Action)
\item 
virtual void \hyperlink{classAI_1_1Algorithm_1_1ReinforcementLearning_a5d576410235e5099f153d21f20a8e5af}{set\-State\-Action\-Value} (const \hyperlink{classAI_1_1StateAction}{State\-Action}$<$ S, A $>$ \&state\-Action, const \hyperlink{namespaceAI_a41b74884a20833db653dded3918e05c3}{A\-I\-::\-F\-L\-O\-A\-T} \&reward)
\item 
const \hyperlink{classAI_1_1StateActionPairContainer}{State\-Action\-Pair\-Container}\\*
$<$ S, A $>$ \& \hyperlink{classAI_1_1Algorithm_1_1ReinforcementLearning_a6b5fe1be9629bf5574d32ae4eeec33f5}{get\-State\-Action\-Pair\-Container} () const 
\item 
void \hyperlink{classAI_1_1Algorithm_1_1ReinforcementLearning_ad889f5f5949cac39d121f57e3027ad0c}{set\-State\-Action\-Pair\-Container} (const \hyperlink{classAI_1_1StateActionPairContainer}{State\-Action\-Pair\-Container}$<$ S, A $>$ \&state\-Action\-Pair\-Container)
\item 
virtual void \hyperlink{classAI_1_1Algorithm_1_1ReinforcementLearning_a25d7fa245a79e61061436dc0f1db90cb}{update} (const \hyperlink{classAI_1_1StateAction}{State\-Action}$<$ S, A $>$ \&current\-State\-Action, const S \&next\-State, const \hyperlink{namespaceAI_a41b74884a20833db653dded3918e05c3}{A\-I\-::\-F\-L\-O\-A\-T} reward, const set$<$ A $>$ \&action\-Set)
\item 
virtual const A \& \hyperlink{classAI_1_1Algorithm_1_1ReinforcementLearning_acb89c1734df6658a422af510b7c36377}{get\-Action} (const S \&current\-State, const set$<$ A $>$ \&action\-Set)
\end{DoxyCompactItemize}
\subsection*{Protected Member Functions}
\begin{DoxyCompactItemize}
\item 
\hypertarget{classAI_1_1Algorithm_1_1ReinforcementLearning_a3efc892a8b36ee3f878c86d15f30883f}{void {\bfseries \-\_\-build\-Action\-Value\-Map} (const set$<$ A $>$ \&action\-Set, const S \&current\-State, map$<$ A, \hyperlink{namespaceAI_a41b74884a20833db653dded3918e05c3}{A\-I\-::\-F\-L\-O\-A\-T} $>$ \&action\-Value\-Map)}\label{classAI_1_1Algorithm_1_1ReinforcementLearning_a3efc892a8b36ee3f878c86d15f30883f}

\end{DoxyCompactItemize}
\subsection*{Protected Attributes}
\begin{DoxyCompactItemize}
\item 
\hypertarget{classAI_1_1Algorithm_1_1ReinforcementLearning_ae8a4204e547054e55542e6f7de4b5dc1}{\hyperlink{namespaceAI_a41b74884a20833db653dded3918e05c3}{A\-I\-::\-F\-L\-O\-A\-T} {\bfseries \-\_\-step\-Size}}\label{classAI_1_1Algorithm_1_1ReinforcementLearning_ae8a4204e547054e55542e6f7de4b5dc1}

\item 
\hypertarget{classAI_1_1Algorithm_1_1ReinforcementLearning_af72ecd83332f502a73f9c5636f433de2}{\hyperlink{namespaceAI_a41b74884a20833db653dded3918e05c3}{A\-I\-::\-F\-L\-O\-A\-T} {\bfseries \-\_\-discount\-Rate}}\label{classAI_1_1Algorithm_1_1ReinforcementLearning_af72ecd83332f502a73f9c5636f433de2}

\item 
\hypertarget{classAI_1_1Algorithm_1_1ReinforcementLearning_aee3318af6590363309fdd04fb9eeebe5}{\hyperlink{classAI_1_1StateActionPairContainer}{State\-Action\-Pair\-Container}$<$ S, A $>$ {\bfseries \-\_\-state\-Action\-Pair\-Container}}\label{classAI_1_1Algorithm_1_1ReinforcementLearning_aee3318af6590363309fdd04fb9eeebe5}

\item 
\hypertarget{classAI_1_1Algorithm_1_1ReinforcementLearning_aa6cddd34af5d8565ea71796434dc17af}{boost\-::shared\-\_\-mutex {\bfseries \-\_\-general\-Lock}}\label{classAI_1_1Algorithm_1_1ReinforcementLearning_aa6cddd34af5d8565ea71796434dc17af}

\item 
\hypertarget{classAI_1_1Algorithm_1_1ReinforcementLearning_a365513e575cf60c0ae6fd5dfcfc54913}{boost\-::shared\-\_\-mutex {\bfseries \-\_\-container\-Lock}}\label{classAI_1_1Algorithm_1_1ReinforcementLearning_a365513e575cf60c0ae6fd5dfcfc54913}

\item 
\hypertarget{classAI_1_1Algorithm_1_1ReinforcementLearning_acc5503fcb31fb030be0c9d302517adcc}{boost\-::shared\-\_\-mutex {\bfseries \-\_\-step\-Size\-Lock}}\label{classAI_1_1Algorithm_1_1ReinforcementLearning_acc5503fcb31fb030be0c9d302517adcc}

\item 
\hypertarget{classAI_1_1Algorithm_1_1ReinforcementLearning_aaa369f14f7f9b9ddb0bf8efb2b8363dd}{boost\-::shared\-\_\-mutex {\bfseries \-\_\-discount\-Rate\-Lock}}\label{classAI_1_1Algorithm_1_1ReinforcementLearning_aaa369f14f7f9b9ddb0bf8efb2b8363dd}

\end{DoxyCompactItemize}
\subsection*{Additional Inherited Members}


\subsection{Detailed Description}
\subsubsection*{template$<$class S, class A$>$class A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning$<$ S, A $>$}

Abstract class for all Reinforcement learning algorithms. 


\begin{DoxyTemplParams}{Template Parameters}
{\em S} & state data type. \\
\hline
{\em A} & action data type.\\
\hline
\end{DoxyTemplParams}
All reinforcement algorithm inherit from this class. 

\subsection{Constructor \& Destructor Documentation}
\hypertarget{classAI_1_1Algorithm_1_1ReinforcementLearning_a4d182d91c68aef838b80843acd044b1e}{\index{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}!Reinforcement\-Learning@{Reinforcement\-Learning}}
\index{Reinforcement\-Learning@{Reinforcement\-Learning}!AI::Algorithm::ReinforcementLearning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}}
\subsubsection[{Reinforcement\-Learning}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class S , class A $>$ {\bf A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}$<$ S, A $>$\-::{\bf Reinforcement\-Learning} (
\begin{DoxyParamCaption}
\item[{{\bf A\-I\-::\-F\-L\-O\-A\-T}}]{step\-Size, }
\item[{{\bf A\-I\-::\-F\-L\-O\-A\-T}}]{discount\-Rate, }
\item[{{\bf Policy\-::\-Policy}$<$ S, A $>$ \&}]{policy}
\end{DoxyParamCaption}
)}}\label{classAI_1_1Algorithm_1_1ReinforcementLearning_a4d182d91c68aef838b80843acd044b1e}

\begin{DoxyParams}{Parameters}
{\em step\-Size} & range $[0.0, 1.0]$. High step size means faster learning, but less precise convergence. \\
\hline
{\em discount\-Rate} & range $[0.0, 1.0]$. High discount rate means more consideration of future events. \\
\hline
{\em policy} & online policy, that is policy used for action selection. \\
\hline
\end{DoxyParams}


\subsection{Member Function Documentation}
\hypertarget{classAI_1_1Algorithm_1_1ReinforcementLearning_ad1d8a8ebb47fb71a53b15b770795e286}{\index{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}!arg\-Max@{arg\-Max}}
\index{arg\-Max@{arg\-Max}!AI::Algorithm::ReinforcementLearning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}}
\subsubsection[{arg\-Max}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class S , class A $>$ A {\bf A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}$<$ S, A $>$\-::arg\-Max (
\begin{DoxyParamCaption}
\item[{const S \&}]{state, }
\item[{const set$<$ A $>$ \&}]{action\-Set}
\end{DoxyParamCaption}
) const}}\label{classAI_1_1Algorithm_1_1ReinforcementLearning_ad1d8a8ebb47fb71a53b15b770795e286}
Returns the action that will most \char`\"{}likely\char`\"{} gives the highest reward from the current state. 
\begin{DoxyParams}{Parameters}
{\em state} & the state to apply the arg\-Max to. \\
\hline
{\em state\-Action} & map of \hyperlink{classAI_1_1StateAction}{State\-Action} to value. \\
\hline
{\em action\-Set} & a set of possible actions. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
the action that will \char`\"{}likely\char`\"{} gives the highest reward. 
\end{DoxyReturn}
\hypertarget{classAI_1_1Algorithm_1_1ReinforcementLearning_aa45b49ec954f6934df4d541b70076bd6}{\index{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}!back\-Up\-State\-Action\-Pair@{back\-Up\-State\-Action\-Pair}}
\index{back\-Up\-State\-Action\-Pair@{back\-Up\-State\-Action\-Pair}!AI::Algorithm::ReinforcementLearning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}}
\subsubsection[{back\-Up\-State\-Action\-Pair}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class S , class A $>$ void {\bf A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}$<$ S, A $>$\-::back\-Up\-State\-Action\-Pair (
\begin{DoxyParamCaption}
\item[{const {\bf State\-Action}$<$ S, A $>$ \&}]{current\-State\-Action, }
\item[{const {\bf A\-I\-::\-F\-L\-O\-A\-T}}]{reward, }
\item[{const {\bf State\-Action}$<$ S, A $>$ \&}]{next\-State\-Action\-Pair}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [virtual]}}}\label{classAI_1_1Algorithm_1_1ReinforcementLearning_aa45b49ec954f6934df4d541b70076bd6}
Does the main back up for all Temporal difference\-: $ Q[S, A] \leftarrow Q[S, A] + \alpha\times [R + \gamma \times max_{A'}Q[S', A'] - Q[S, A] ]$ 
\begin{DoxyParams}{Parameters}
{\em current\-State\-Action} & $(S, A)$, current state-\/action pair. \\
\hline
{\em reward} & $R$, reward after $(S, A)$. \\
\hline
{\em next\-State\-Action\-Pair} & $(S', A')$, next state-\/action pair. \\
\hline
\end{DoxyParams}


Reimplemented in \hyperlink{classAI_1_1Algorithm_1_1DynaQRLMP_a7b3b5f3706744290b12c19f786e5e4e4}{A\-I\-::\-Algorithm\-::\-Dyna\-Q\-R\-L\-M\-P$<$ S, A $>$}, and \hyperlink{classAI_1_1Algorithm_1_1DynaQCCRLCCMP_aebff9b81db5bd2ae33bd3d6662539bc0}{A\-I\-::\-Algorithm\-::\-Dyna\-Q\-C\-C\-R\-L\-C\-C\-M\-P$<$ S, A $>$}.

\hypertarget{classAI_1_1Algorithm_1_1ReinforcementLearning_acb89c1734df6658a422af510b7c36377}{\index{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}!get\-Action@{get\-Action}}
\index{get\-Action@{get\-Action}!AI::Algorithm::ReinforcementLearning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}}
\subsubsection[{get\-Action}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class S , class A $>$ const A \& {\bf A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}$<$ S, A $>$\-::get\-Action (
\begin{DoxyParamCaption}
\item[{const S \&}]{state, }
\item[{const set$<$ A $>$ \&}]{action\-Set}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [virtual]}}}\label{classAI_1_1Algorithm_1_1ReinforcementLearning_acb89c1734df6658a422af510b7c36377}
A policy that varies between algorithms. 

Implements \hyperlink{classAI_1_1Algorithm_1_1LearningAlgorithm_afeca4eded9bc0a02312ccbbfd05f8daa}{A\-I\-::\-Algorithm\-::\-Learning\-Algorithm$<$ S, A $>$}.

\hypertarget{classAI_1_1Algorithm_1_1ReinforcementLearning_a04edb957e23dde9c6733668ad844c32b}{\index{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}!get\-Discount\-Rate@{get\-Discount\-Rate}}
\index{get\-Discount\-Rate@{get\-Discount\-Rate}!AI::Algorithm::ReinforcementLearning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}}
\subsubsection[{get\-Discount\-Rate}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class S , class A $>$ {\bf A\-I\-::\-F\-L\-O\-A\-T} {\bf A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}$<$ S, A $>$\-::get\-Discount\-Rate (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [virtual]}}}\label{classAI_1_1Algorithm_1_1ReinforcementLearning_a04edb957e23dde9c6733668ad844c32b}
\begin{DoxyReturn}{Returns}
current discount rate. 
\end{DoxyReturn}
\hypertarget{classAI_1_1Algorithm_1_1ReinforcementLearning_a9f31822bf51b07d17b31d7683d7e25a2}{\index{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}!get\-Learning\-Action@{get\-Learning\-Action}}
\index{get\-Learning\-Action@{get\-Learning\-Action}!AI::Algorithm::ReinforcementLearning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}}
\subsubsection[{get\-Learning\-Action}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class S , class A $>$ const A \& {\bf A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}$<$ S, A $>$\-::get\-Learning\-Action (
\begin{DoxyParamCaption}
\item[{const S \&}]{current\-State, }
\item[{const set$<$ A $>$ \&}]{action\-Set}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}}}\label{classAI_1_1Algorithm_1_1ReinforcementLearning_a9f31822bf51b07d17b31d7683d7e25a2}
Get Action with respect to learning/offline policy. 
\begin{DoxyParams}{Parameters}
{\em current\-State} & state to acquire state-\/action values from. \\
\hline
{\em action\-Set} & Set of actions. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
Action with respect to learning/offline policy. 
\end{DoxyReturn}
\hypertarget{classAI_1_1Algorithm_1_1ReinforcementLearning_a6b5fe1be9629bf5574d32ae4eeec33f5}{\index{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}!get\-State\-Action\-Pair\-Container@{get\-State\-Action\-Pair\-Container}}
\index{get\-State\-Action\-Pair\-Container@{get\-State\-Action\-Pair\-Container}!AI::Algorithm::ReinforcementLearning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}}
\subsubsection[{get\-State\-Action\-Pair\-Container}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class S , class A $>$ const {\bf A\-I\-::\-State\-Action\-Pair\-Container}$<$ S, A $>$ \& {\bf A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}$<$ S, A $>$\-::get\-State\-Action\-Pair\-Container (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [inline]}}}\label{classAI_1_1Algorithm_1_1ReinforcementLearning_a6b5fe1be9629bf5574d32ae4eeec33f5}
\begin{DoxyReturn}{Returns}
state-\/action pair container. 
\end{DoxyReturn}
\hypertarget{classAI_1_1Algorithm_1_1ReinforcementLearning_ad078677d92b33df4ae7d3c78e040b766}{\index{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}!get\-State\-Action\-Value@{get\-State\-Action\-Value}}
\index{get\-State\-Action\-Value@{get\-State\-Action\-Value}!AI::Algorithm::ReinforcementLearning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}}
\subsubsection[{get\-State\-Action\-Value}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class S , class A $>$ {\bf A\-I\-::\-F\-L\-O\-A\-T} {\bf A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}$<$ S, A $>$\-::get\-State\-Action\-Value (
\begin{DoxyParamCaption}
\item[{const {\bf State\-Action}$<$ S, A $>$ \&}]{state\-Action}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [virtual]}}}\label{classAI_1_1Algorithm_1_1ReinforcementLearning_ad078677d92b33df4ae7d3c78e040b766}

\begin{DoxyParams}{Parameters}
{\em state\-Action} & to acquire a value of. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
the value of state-\/action pair. 
\end{DoxyReturn}


Implements \hyperlink{classAI_1_1Algorithm_1_1LearningAlgorithm_a1044b2558109e8dd3d3bf5bedb9723b5}{A\-I\-::\-Algorithm\-::\-Learning\-Algorithm$<$ S, A $>$}.

\hypertarget{classAI_1_1Algorithm_1_1ReinforcementLearning_a13e6c161a33644183d3d357971eeaaf5}{\index{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}!get\-Step\-Size@{get\-Step\-Size}}
\index{get\-Step\-Size@{get\-Step\-Size}!AI::Algorithm::ReinforcementLearning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}}
\subsubsection[{get\-Step\-Size}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class S , class A $>$ {\bf A\-I\-::\-F\-L\-O\-A\-T} {\bf A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}$<$ S, A $>$\-::get\-Step\-Size (
\begin{DoxyParamCaption}
{}
\end{DoxyParamCaption}
) const\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [virtual]}}}\label{classAI_1_1Algorithm_1_1ReinforcementLearning_a13e6c161a33644183d3d357971eeaaf5}
\begin{DoxyReturn}{Returns}
current step\-Size. 
\end{DoxyReturn}
\hypertarget{classAI_1_1Algorithm_1_1ReinforcementLearning_a1fc1e11a3ddb4377c4d6813a95ce87f4}{\index{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}!set\-Discount\-Rate@{set\-Discount\-Rate}}
\index{set\-Discount\-Rate@{set\-Discount\-Rate}!AI::Algorithm::ReinforcementLearning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}}
\subsubsection[{set\-Discount\-Rate}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class S , class A $>$ void {\bf A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}$<$ S, A $>$\-::set\-Discount\-Rate (
\begin{DoxyParamCaption}
\item[{{\bf A\-I\-::\-F\-L\-O\-A\-T}}]{discount\-Rate}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [virtual]}}}\label{classAI_1_1Algorithm_1_1ReinforcementLearning_a1fc1e11a3ddb4377c4d6813a95ce87f4}

\begin{DoxyParams}{Parameters}
{\em discount\-Rate} & \\
\hline
\end{DoxyParams}
\hypertarget{classAI_1_1Algorithm_1_1ReinforcementLearning_ad889f5f5949cac39d121f57e3027ad0c}{\index{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}!set\-State\-Action\-Pair\-Container@{set\-State\-Action\-Pair\-Container}}
\index{set\-State\-Action\-Pair\-Container@{set\-State\-Action\-Pair\-Container}!AI::Algorithm::ReinforcementLearning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}}
\subsubsection[{set\-State\-Action\-Pair\-Container}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class S , class A $>$ void {\bf A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}$<$ S, A $>$\-::set\-State\-Action\-Pair\-Container (
\begin{DoxyParamCaption}
\item[{const {\bf State\-Action\-Pair\-Container}$<$ S, A $>$ \&}]{state\-Action\-Pair\-Container}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}}}\label{classAI_1_1Algorithm_1_1ReinforcementLearning_ad889f5f5949cac39d121f57e3027ad0c}

\begin{DoxyParams}{Parameters}
{\em state\-Action\-Pair\-Container} & set state-\/action pair container. \\
\hline
\end{DoxyParams}
\hypertarget{classAI_1_1Algorithm_1_1ReinforcementLearning_a5d576410235e5099f153d21f20a8e5af}{\index{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}!set\-State\-Action\-Value@{set\-State\-Action\-Value}}
\index{set\-State\-Action\-Value@{set\-State\-Action\-Value}!AI::Algorithm::ReinforcementLearning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}}
\subsubsection[{set\-State\-Action\-Value}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class S , class A $>$ void {\bf A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}$<$ S, A $>$\-::set\-State\-Action\-Value (
\begin{DoxyParamCaption}
\item[{const {\bf State\-Action}$<$ S, A $>$ \&}]{state\-Action, }
\item[{const {\bf A\-I\-::\-F\-L\-O\-A\-T} \&}]{reward}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [virtual]}}}\label{classAI_1_1Algorithm_1_1ReinforcementLearning_a5d576410235e5099f153d21f20a8e5af}
$ Q[ S, A ] \leftarrow R $ 
\begin{DoxyParams}{Parameters}
{\em state\-Action} & to retrieve value from. \\
\hline
{\em reward} & to set to the new state-\/action value. \\
\hline
\end{DoxyParams}
\hypertarget{classAI_1_1Algorithm_1_1ReinforcementLearning_a04932645faa6c385e4c587f7f845b484}{\index{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}!set\-Step\-Size@{set\-Step\-Size}}
\index{set\-Step\-Size@{set\-Step\-Size}!AI::Algorithm::ReinforcementLearning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}}
\subsubsection[{set\-Step\-Size}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class S , class A $>$ void {\bf A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}$<$ S, A $>$\-::set\-Step\-Size (
\begin{DoxyParamCaption}
\item[{{\bf A\-I\-::\-F\-L\-O\-A\-T}}]{step\-Size}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [virtual]}}}\label{classAI_1_1Algorithm_1_1ReinforcementLearning_a04932645faa6c385e4c587f7f845b484}

\begin{DoxyParams}{Parameters}
{\em step\-Size} & set the step size of Reinforcement Learning. \\
\hline
\end{DoxyParams}
\hypertarget{classAI_1_1Algorithm_1_1ReinforcementLearning_a25d7fa245a79e61061436dc0f1db90cb}{\index{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}!update@{update}}
\index{update@{update}!AI::Algorithm::ReinforcementLearning@{A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}}
\subsubsection[{update}]{\setlength{\rightskip}{0pt plus 5cm}template$<$class S , class A $>$ void {\bf A\-I\-::\-Algorithm\-::\-Reinforcement\-Learning}$<$ S, A $>$\-::update (
\begin{DoxyParamCaption}
\item[{const {\bf State\-Action}$<$ S, A $>$ \&}]{current\-State\-Action, }
\item[{const S \&}]{next\-State, }
\item[{const {\bf A\-I\-::\-F\-L\-O\-A\-T}}]{reward, }
\item[{const set$<$ A $>$ \&}]{action\-Set}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [virtual]}}}\label{classAI_1_1Algorithm_1_1ReinforcementLearning_a25d7fa245a79e61061436dc0f1db90cb}
Update the state\-Action map. 
\begin{DoxyParams}{Parameters}
{\em current\-State} & current\-State agent is in. \\
\hline
{\em current\-Action} & action taken by agent by being in current\-State. \\
\hline
{\em next\-State} & next\-State by taking current\-Action in current\-State. \\
\hline
{\em reward} & reward of current\-State\-Action. \\
\hline
{\em action\-Set} & A set of all actions. \\
\hline
\end{DoxyParams}


Implements \hyperlink{classAI_1_1Algorithm_1_1LearningAlgorithm_a7d216d791e558e15a73083af6257ed72}{A\-I\-::\-Algorithm\-::\-Learning\-Algorithm$<$ S, A $>$}.



Reimplemented in \hyperlink{classAI_1_1Algorithm_1_1DynaQPrioritizeSweeping_ad08b55f3cf927189dd31abf9fc1c2959}{A\-I\-::\-Algorithm\-::\-Dyna\-Q\-Prioritize\-Sweeping$<$ S, A $>$}, \hyperlink{classAI_1_1Algorithm_1_1DynaQET_a53b0e06842fbb802acfa5384a84ad448}{A\-I\-::\-Algorithm\-::\-Dyna\-Q\-E\-T$<$ S, A $>$}, \hyperlink{classAI_1_1Algorithm_1_1DynaQ_a4542226b17db4ed8a2c5ec17d37dc42f}{A\-I\-::\-Algorithm\-::\-Dyna\-Q$<$ S, A $>$}, \hyperlink{classAI_1_1Algorithm_1_1SarsaET_adf13376b7ec8fdfa2b19ffadb1aa81e7}{A\-I\-::\-Algorithm\-::\-Sarsa\-E\-T$<$ S, A $>$}, \hyperlink{classAI_1_1Algorithm_1_1Sarsa_ae1d62478d3e31cace3fb594e05f83d1c}{A\-I\-::\-Algorithm\-::\-Sarsa$<$ S, A $>$}, \hyperlink{classAI_1_1Algorithm_1_1QLearning_a042e1987ce21a94f59603c4cb1eeed82}{A\-I\-::\-Algorithm\-::\-Q\-Learning$<$ S, A $>$}, \hyperlink{classAI_1_1Algorithm_1_1QLearningET_a9a245dcb3ca8f26b37e5a6daa6d4a898}{A\-I\-::\-Algorithm\-::\-Q\-Learning\-E\-T$<$ S, A $>$}, and \hyperlink{classAI_1_1Algorithm_1_1DynaQCC_ae23b8f0afbb9fc5024aef9ce720c9b84}{A\-I\-::\-Algorithm\-::\-Dyna\-Q\-C\-C$<$ S, A $>$}.



The documentation for this class was generated from the following file\-:\begin{DoxyCompactItemize}
\item 
Algorithms/\-Reinforcement\-Learning/Reinforcement\-Learning.\-h\end{DoxyCompactItemize}
